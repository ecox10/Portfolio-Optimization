{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd568c3a-9173-4477-93dd-42091cd857b7",
   "metadata": {},
   "source": [
    "# Black-Litterman Analysis on Eurostat Data\n",
    "Ellie Cox\n",
    "\n",
    "This file will conduct markowitz and black-litterman analysis on energy supply data retrieved from eurostat. \n",
    "First with the full data, then taking the average when excluding one country at a time, the average when excluding one year of data at a time, and lastly using a randomly selected 75\\% of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311d8021-e604-48a8-a069-b1d2f41a9e31",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f05eb-5a7e-4c73-ba00-72d00cfb6e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stat\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import random\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60559c15-0360-4e94-bc58-5046ab921ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypfopt as pyp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e4ad61-878c-421e-9193-51611ec527e0",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac4b9a-bbe5-4478-b7ab-ea052f8b9c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data using pandas\n",
    "data = pd.read_csv(\"/Users/elizabeth/Documents/Master's Project/Data/EU_TotalEnergySupply.csv\")\n",
    "\n",
    "# Create list of column names\n",
    "data.columns.values.tolist()\n",
    "# Rename columns to make life easier\n",
    "data.columns = [c.replace(' ', '_') for c in data.columns] # remove spaces\n",
    "data.columns = [c.replace('(', '') for c in data.columns] # remove open parenthesis\n",
    "data.columns = [c.replace(')', '') for c in data.columns] # remove close parenthesis\n",
    "data.columns.values.tolist()\n",
    "\n",
    "# Get rid of ':' and shorten other names\n",
    "data = data.replace([':'],'')\n",
    "data = data.replace(['European Union - 27 countries (from 2020)'],'EU')\n",
    "data = data.replace(['Euro area - 19 countries  (from 2015)'],'Euro area')\n",
    "data = data.replace(['Germany (until 1990 former territory of the FRG)'],'Germany')\n",
    "data = data.replace(['Kosovo (under United Nations Security Council Resolution 1244/99)'],'Kosovo')\n",
    "\n",
    "# Change Data type to numeric\n",
    "data[data.columns[2:]] = data[data.columns[2:]].apply(pd.to_numeric, errors ='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d60d54-bdbc-484a-98ba-4b82420fc1ad",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "Missing Data is handled in 2 ways:\n",
    "\n",
    "    1) Replacing missing data with the country's average\n",
    "    2) Dropping it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e436b5-ef22-417a-a67e-a1c6ed2761ec",
   "metadata": {},
   "source": [
    "## Impute Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b973abd-1a72-4e1b-9849-c5d1a2422438",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1) Impute data with the average\n",
    "frames = []\n",
    "for i in list(set(data['Country'])):\n",
    "            df_country = data[data['Country'] == i] \n",
    "            df_country['Total_GWH'].fillna(df_country['Total_GWH'].mean(),inplace = True)\n",
    "            df_country['Solid_fossil_fuels'].fillna(df_country['Solid_fossil_fuels'].mean(), inplace = True)\n",
    "            df_country['Peat_and_peat_products'].fillna(df_country['Peat_and_peat_products'].mean(), inplace = True)\n",
    "            df_country['Solar_Thermal'].fillna(df_country['Solar_Thermal'].mean(), inplace = True)\n",
    "            df_country['Oil_and_petroleum_products'].fillna(df_country['Oil_and_petroleum_products'].mean(), inplace = True)\n",
    "            df_country['Natural_gas'].fillna(df_country['Natural_gas'].mean(), inplace = True)\n",
    "            df_country['Renewables_and_biofuels'].fillna(df_country['Renewables_and_biofuels'].mean(), inplace = True)\n",
    "            df_country['Nuclear_heat'].fillna(df_country['Nuclear_heat'].mean(),inplace = True)\n",
    "            df_country['Hydro'].fillna(df_country['Hydro'].mean(),inplace = True)\n",
    "            df_country['Geothermal'].fillna(df_country['Geothermal'].mean(),inplace = True)\n",
    "            df_country['Ambient_Heat'].fillna(df_country['Ambient_Heat'].mean(),inplace = True)\n",
    "            df_country['Tide_wave_and_ocean'].fillna(df_country['Tide_wave_and_ocean'].mean(),inplace = True)\n",
    "            df_country['Wind'].fillna(df_country['Wind'].mean(),inplace = True)\n",
    "            df_country['Biofuels_solid'].fillna(df_country['Biofuels_solid'].mean(),inplace = True)\n",
    "            df_country['Biofuels_other'].fillna(df_country['Biofuels_other'].mean(),inplace = True)\n",
    "            df_country['Biofuels'].fillna(df_country['Biofuels'].mean(),inplace = True)\n",
    "            frames.append(df_country)\n",
    "            final_df = pd.concat(frames)\n",
    "data_impute = final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3862a-f9be-4989-9165-75fccb76c238",
   "metadata": {},
   "source": [
    "## Define Black-Litterman Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2e255a-0f82-4baf-8523-61114e945a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bl(n_assets, n_obs, return_vec):\n",
    "    '''\n",
    "    This function evaluates the equillibrium returns of a portfolio and generates the sample\n",
    "    Inputs: \n",
    "    n_assets: Number of assets\n",
    "    n_obs: Number of observations\n",
    "    return_vec: A matrix of returns of shape n_obs x n_assets (a np.array)\n",
    "    view: a vector of investor views of length n_assets\n",
    "    Returns: \n",
    "    weights: optimal weights\n",
    "    bl_returns: BL returns\n",
    "    S: BL risk\n",
    "    '''\n",
    "    R = pd.Series(np.mean(return_vec, axis = 0)) # Market returns\n",
    "    pi = R - 0 * np.ones(n_assets) # equillibrium risk premiums where R_f = 0\n",
    "    r = np.cov(return_vec.T)\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    cov_struct = rng.multivariate_normal(np.zeros(n_assets), cov = r, size = n_obs)\n",
    "    S = pyp.risk_models.CovarianceShrinkage(cov_struct).ledoit_wolf()\n",
    "    delta = pyp.black_litterman.market_implied_risk_aversion(pi, risk_free_rate=0.5)\n",
    "    \n",
    "    market_prior = pd.Series(np.mean(return_vec, axis = 0))\n",
    "    #views = pd.Series(view)\n",
    "    Q = np.reshape(np.mean(return_vec, axis = 0),(n_assets,1))[0:4,:] # 4 views\n",
    "    P = np.array(\n",
    "        [\n",
    "            np.random.dirichlet(np.ones(n_assets), size=1)[0],\n",
    "            np.random.dirichlet(np.ones(n_assets), size=1)[0],\n",
    "            np.random.dirichlet(np.ones(n_assets), size=1)[0],\n",
    "            np.random.dirichlet(np.ones(n_assets), size=1)[0],\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    bl = pyp.BlackLittermanModel(S, pi=market_prior, Q = Q, P = P)\n",
    "    bl_return = bl.bl_returns()\n",
    "\n",
    "    ef = pyp.EfficientFrontier(bl_return, r)\n",
    "    bl.bl_weights(delta)\n",
    "    weights = bl.clean_weights()\n",
    "\n",
    "    S_bl = bl.bl_cov()\n",
    "    return weights, bl_return, S_bl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a9d488-d4bd-4452-93c7-6bd6a24b35a4",
   "metadata": {},
   "source": [
    "## Analysis on Imputed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf7b97-09ae-4c45-9425-e895bb4a8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdat = data_impute.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce7b932-5953-4957-ae3b-34a0819303b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run one optimization - this returns the results for the full data set and will report the \n",
    "## results of one optimization instead of an average \n",
    "\n",
    "## Set view - I'm going to start by using the median - this is only used when I use absolute confidence\n",
    "view = np.array(np.median(cdat, axis = 0))\n",
    "\n",
    "full_wt, full_rt, full_rsk = bl(cdat.shape[1], cdat.shape[0], np.array(cdat))\n",
    "weight_full = list(full_wt.items())\n",
    "w_full = [x[1] for x in weight_full]\n",
    "weight_full = w_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5966722-5562-4ff9-ad6d-31d0d232958d",
   "metadata": {},
   "source": [
    "## Calculate average over dropping one country at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58085d61-f5c7-46ad-8842-8d6aa7de1a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full data set - with country and year for filtering\n",
    "cdat = data_impute.loc[:,['Country','Year','Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd99f93-26ce-449f-91cc-cda15a036161",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_country = np.zeros((len(data.groupby('Country')),len(cdat.T)-2))\n",
    "return_res = np.zeros((len(data.groupby('Country')),len(cdat.T)-2))\n",
    "risks_res = np.zeros((len(data.groupby('Country')),len(cdat.T)-2))\n",
    "\n",
    "for i in range(len(data.groupby('Country'))):\n",
    "    country_dat = cdat.loc[(cdat.Country != cdat.Country.unique()[i])]\n",
    "    country_dat = country_dat.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]\n",
    "    ## Set view - I'm going to start by using the median\n",
    "    view = np.array(np.median(country_dat, axis = 0))\n",
    "    weights, returns, risks = bl(country_dat.shape[1], country_dat.shape[0], np.array(country_dat))\n",
    "    weights = list(weights.items())\n",
    "    w = [x[1] for x in weights]\n",
    "    weight_country[i,:] = w\n",
    "    return_res[i,:] = np.array(returns).T\n",
    "    risks_res[i,:] = np.diagonal(np.array(risks))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c9a76a-b2a9-42f1-be71-e6034142c2f1",
   "metadata": {},
   "source": [
    "## Calculate average over dropping one year at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bafb8f9-784b-4068-b8d7-7eb1042cb9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_year = np.zeros((len(data.groupby('Year')),len(cdat.T)-2))\n",
    "return_res = np.zeros((len(data.groupby('Year')),len(cdat.T)-2))\n",
    "risks_res = np.zeros((len(data.groupby('Year')),len(cdat.T)-2))\n",
    "\n",
    "for i in range(len(data.groupby('Year'))):\n",
    "    year_dat = cdat.loc[(cdat.Year != cdat.Year.unique()[i])]\n",
    "    year_dat = year_dat.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]\n",
    "    ## Set view - I'm going to start by using the median\n",
    "    view = np.array(np.median(year_dat, axis = 0))\n",
    "    weights, returns, risks = bl(year_dat.shape[1], year_dat.shape[0], np.array(year_dat))\n",
    "    weights = list(weights.items())\n",
    "    w = [x[1] for x in weights]\n",
    "    weight_year[i,:] = w\n",
    "    return_res[i,:] = np.array(returns).T\n",
    "    risks_res[i,:] = np.diagonal(np.array(risks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc06b05-0deb-40c0-b794-e058ff2f56e8",
   "metadata": {},
   "source": [
    "## Drop Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef06fec-43d9-4b87-a556-c55094104275",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba8799-7150-45df-84c2-807880a63caa",
   "metadata": {},
   "source": [
    "Full results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6b326-0dd7-419a-8ee4-9cfbf034550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset Data\n",
    "cdat = data_drop.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d06f88-d8d2-4b23-8f43-7d9cbd3c2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run one optimization - this returns the results for the full data set and will report the \n",
    "## results of one optimization instead of an average \n",
    "\n",
    "## Set view - I'm going to start by using the median\n",
    "view = np.array(np.median(cdat, axis = 0))\n",
    "\n",
    "full_wt, full_rt, full_rsk = bl(cdat.shape[1], cdat.shape[0], np.array(cdat))\n",
    "weight_full = list(full_wt.items())\n",
    "w_full = [x[1] for x in weight_full]\n",
    "weight_full_drop = w_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158420b6-6e34-4422-971b-8752b526304a",
   "metadata": {},
   "source": [
    "Calculate average over dropping one country at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca972db6-f465-4dd4-becf-5b70f8f5fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full data set - with country and year for filtering\n",
    "cdat = data_drop.loc[:,['Country','Year','Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258660e0-5285-4af7-b439-b06577ac8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_country_drop = np.zeros((len(data.groupby('Country')),len(cdat.T)-2))\n",
    "return_res = np.zeros((len(data.groupby('Country')),len(cdat.T)-2))\n",
    "risks_res = np.zeros((len(data.groupby('Country')),len(cdat.T)-2))\n",
    "\n",
    "for i in range(len(data.groupby('Country'))):\n",
    "    country_dat = cdat.loc[(cdat.Country != cdat.Country.unique()[i])]\n",
    "    country_dat = country_dat.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]\n",
    "    ## Set view - I'm going to start by using the median\n",
    "    view = np.array(np.median(country_dat, axis = 0))\n",
    "    weights, returns, risks = bl(country_dat.shape[1], country_dat.shape[0], np.array(country_dat))\n",
    "    weights = list(weights.items())\n",
    "    w = [x[1] for x in weights]\n",
    "    weight_country_drop[i,:] = w\n",
    "    return_res[i,:] = np.array(returns).T\n",
    "    risks_res[i,:] = np.diagonal(np.array(risks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4fb4a2-9794-485b-b539-6e91ab6b7b2e",
   "metadata": {},
   "source": [
    "Calculate average over dropping one year at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5469a3-6e32-41d9-87b1-acfa35caf8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_year_drop = np.zeros((len(data.groupby('Year')),len(cdat.T)-2))\n",
    "return_res = np.zeros((len(data.groupby('Year')),len(cdat.T)-2))\n",
    "risks_res = np.zeros((len(data.groupby('Year')),len(cdat.T)-2))\n",
    "\n",
    "for i in range(len(data.groupby('Year'))):\n",
    "    year_dat = cdat.loc[(cdat.Year != cdat.Year.unique()[i])]\n",
    "    year_dat = year_dat.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]\n",
    "    ## Set view - I'm going to start by using the median\n",
    "    view = np.array(np.median(year_dat, axis = 0))\n",
    "    weights, returns, risks = bl(year_dat.shape[1], year_dat.shape[0], np.array(year_dat))\n",
    "    weights = list(weights.items())\n",
    "    w = [x[1] for x in weights]\n",
    "    weight_year_drop[i,:] = w\n",
    "    return_res[i,:] = np.array(returns).T\n",
    "    risks_res[i,:] = np.diagonal(np.array(risks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8746211-ee4b-4d9e-bdc2-8c95b17b1ffe",
   "metadata": {},
   "source": [
    "## Drop random 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b5ded-fe87-43cc-bbea-eaf8da572258",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdat = data_impute.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a5869c-7039-4658-a30c-309fbc763089",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_rand = np.zeros((100,len(cdat.T)))\n",
    "return_res = np.zeros((100,len(cdat.T)))\n",
    "risks_res = np.zeros((100,len(cdat.T)))\n",
    "\n",
    "for i in range(100):\n",
    "    ## Set view - I'm going to start by using the median\n",
    "    view = np.array(np.median(cdat, axis = 0))\n",
    "    \n",
    "    # Randomly take out 20% of the data\n",
    "    _80_perct = int(cdat.shape[0]*4/5)\n",
    "    cdat = cdat.iloc[random.sample(list(range(cdat.shape[0])), _80_perct)]\n",
    "\n",
    "    full_wt, full_rt, full_rsk = bl(cdat.shape[1], cdat.shape[0], np.array(cdat))\n",
    "    weight_full = list(full_wt.items())\n",
    "    w_full = [x[1] for x in weight_full]\n",
    "    full_wt = w_full\n",
    "    weight_rand[i,:] = full_wt\n",
    "    return_res[i,:] = full_rt\n",
    "    risks_res[i,:] = np.diagonal(np.array(full_rsk))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec7cd86-2bbf-4fb0-bf19-62d7c044acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdat = data_drop.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d34dde-939a-4625-bc8e-8158f5a8b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_rand_drop = np.zeros((100,len(cdat.T)))\n",
    "return_res = np.zeros((100,len(cdat.T)))\n",
    "risks_res = np.zeros((100,len(cdat.T)))\n",
    "\n",
    "for i in range(100):\n",
    "    ## Set view - I'm going to start by using the median\n",
    "    view = np.array(np.median(cdat, axis = 0))\n",
    "    \n",
    "    # Randomly take out 20% of the data\n",
    "    _80_perct = int(cdat.shape[0]*4/5)\n",
    "    cdat = cdat.iloc[random.sample(list(range(cdat.shape[0])), _80_perct)]\n",
    "\n",
    "    full_wt, full_rt, full_rsk = bl(cdat.shape[1], cdat.shape[0], np.array(cdat))\n",
    "    weight_full = list(full_wt.items())\n",
    "    w_full = [x[1] for x in weight_full]\n",
    "    full_wt = w_full\n",
    "    weight_rand_drop[i,:] = full_wt\n",
    "    return_res[i,:] = full_rt\n",
    "    risks_res[i,:] = np.diagonal(np.array(full_rsk))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7735eb21-a926-4d4f-8cc6-01f05ed68b49",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03092298-1cd3-47f7-8d79-4d9d521286b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLResults_Weights = [weight_full, weight_country, weight_year, weight_rand, \n",
    "                              weight_full_drop, weight_country_drop, weight_year_drop, weight_rand_drop]\n",
    "\n",
    "file_name = \"EUBLResultsWeights.pkl\"\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(BLResults_Weights, open_file)\n",
    "open_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
