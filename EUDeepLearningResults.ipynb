{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "041c731c-ed54-4387-acc0-35938b3f204d",
   "metadata": {},
   "source": [
    "# Deep Learning Results for Eurostat Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16648401-054b-45a2-918b-47afc2d4d97c",
   "metadata": {},
   "source": [
    "This file performs Deep Learning Analysis for on Eurostat Energy supply data where missing data is \n",
    "1) imputed with the mean\n",
    "2) excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba02d408-4f9f-4f14-96c7-17c907aff135",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fc05862-7da9-4d70-8775-31f2c64a9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from keras.callbacks import EarlyStopping\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3ef7b4e-e581-40c5-b8d1-224fa7b12c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporarily surpress output\n",
    "sys.stdout = open(os.devnull, \"w\")\n",
    "sys.stderr = open(os.devnull, \"w\")\n",
    "# to return it\n",
    "#sys.stdout = sys.__stdout__\n",
    "#sys.stderr = sys.__stderr__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77223d6-f5e2-42be-bcbb-8e4403252749",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0addd7ef-43b0-48bc-a176-3f35b1f68eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data using pandas\n",
    "data_full = pd.read_csv(\"/Users/elizabeth/Documents/Master's Project/Data/EU_TotalEnergySupply.csv\")\n",
    "\n",
    "# Create list of column names\n",
    "data_full.columns.values.tolist()\n",
    "# Rename columns to make life easier\n",
    "data_full.columns = [c.replace(' ', '_') for c in data_full.columns] # remove spaces\n",
    "data_full.columns = [c.replace('(', '') for c in data_full.columns] # remove open parenthesis\n",
    "data_full.columns = [c.replace(')', '') for c in data_full.columns] # remove close parenthesis\n",
    "data_full.columns.values.tolist()\n",
    "\n",
    "# Get rid of ':' and shorten other names\n",
    "data_full = data_full.replace([':'],'')\n",
    "data_full = data_full.replace(['European Union - 27 countries (from 2020)'],'EU')\n",
    "data_full = data_full.replace(['Euro area - 19 countries  (from 2015)'],'Euro area')\n",
    "data_full = data_full.replace(['Germany (until 1990 former territory of the FRG)'],'Germany')\n",
    "data_full = data_full.replace(['Kosovo (under United Nations Security Council Resolution 1244/99)'],'Kosovo')\n",
    "\n",
    "# Change Data type to numeric\n",
    "data_full[data_full.columns[2:]] = data_full[data_full.columns[2:]].apply(pd.to_numeric, errors ='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27404a51-b3c7-4644-a09d-e914b835cd23",
   "metadata": {},
   "source": [
    "Impute the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac09ca10-be64-4ae8-8b9e-8007f5b072ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elizabeth/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:4463: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "source": [
    "## 1) Impute data with the average\n",
    "frames = []\n",
    "for i in list(set(data_full['Country'])):\n",
    "            df_country = data_full[data_full['Country'] == i] \n",
    "            df_country['Total_GWH'].fillna(df_country['Total_GWH'].mean(),inplace = True)\n",
    "            df_country['Solid_fossil_fuels'].fillna(df_country['Solid_fossil_fuels'].mean(), inplace = True)\n",
    "            df_country['Peat_and_peat_products'].fillna(df_country['Peat_and_peat_products'].mean(), inplace = True)\n",
    "            df_country['Solar_Thermal'].fillna(df_country['Solar_Thermal'].mean(), inplace = True)\n",
    "            df_country['Oil_and_petroleum_products'].fillna(df_country['Oil_and_petroleum_products'].mean(), inplace = True)\n",
    "            df_country['Natural_gas'].fillna(df_country['Natural_gas'].mean(), inplace = True)\n",
    "            df_country['Renewables_and_biofuels'].fillna(df_country['Renewables_and_biofuels'].mean(), inplace = True)\n",
    "            df_country['Nuclear_heat'].fillna(df_country['Nuclear_heat'].mean(),inplace = True)\n",
    "            df_country['Hydro'].fillna(df_country['Hydro'].mean(),inplace = True)\n",
    "            df_country['Geothermal'].fillna(df_country['Geothermal'].mean(),inplace = True)\n",
    "            df_country['Ambient_Heat'].fillna(df_country['Ambient_Heat'].mean(),inplace = True)\n",
    "            df_country['Tide_wave_and_ocean'].fillna(df_country['Tide_wave_and_ocean'].mean(),inplace = True)\n",
    "            df_country['Wind'].fillna(df_country['Wind'].mean(),inplace = True)\n",
    "            df_country['Biofuels_solid'].fillna(df_country['Biofuels_solid'].mean(),inplace = True)\n",
    "            df_country['Biofuels_other'].fillna(df_country['Biofuels_other'].mean(),inplace = True)\n",
    "            df_country['Biofuels'].fillna(df_country['Biofuels'].mean(),inplace = True)\n",
    "            frames.append(df_country)\n",
    "            final_df = pd.concat(frames)\n",
    "data_impute = final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b81495-321d-43e0-9651-f17b198f34ba",
   "metadata": {},
   "source": [
    "## Results for Imputed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41314ef0-f972-428e-a1bb-de099b56ceec",
   "metadata": {},
   "source": [
    "Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a12ce0f3-fdb6-4b42-9ee5-8d83ef431280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total_GWH</th>\n",
       "      <th>Solid_fossil_fuels</th>\n",
       "      <th>Peat_and_peat_products</th>\n",
       "      <th>Oil_and_petroleum_products</th>\n",
       "      <th>Natural_gas</th>\n",
       "      <th>Renewables_and_biofuels</th>\n",
       "      <th>Nuclear_heat</th>\n",
       "      <th>Solar_Thermal</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Hydro</th>\n",
       "      <th>Geothermal</th>\n",
       "      <th>Ambient_Heat</th>\n",
       "      <th>Tide_wave_and_ocean</th>\n",
       "      <th>Biofuels_solid</th>\n",
       "      <th>Biofuels_other</th>\n",
       "      <th>Biofuels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Poland</td>\n",
       "      <td>2020</td>\n",
       "      <td>1192325.452</td>\n",
       "      <td>475838.038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>337028.005</td>\n",
       "      <td>202831.135</td>\n",
       "      <td>150618.088</td>\n",
       "      <td>0.000</td>\n",
       "      <td>932.074</td>\n",
       "      <td>15800.049</td>\n",
       "      <td>2118.337</td>\n",
       "      <td>298.189</td>\n",
       "      <td>3467.032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108513.529</td>\n",
       "      <td>22.718</td>\n",
       "      <td>108536.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Poland</td>\n",
       "      <td>2019</td>\n",
       "      <td>1221101.488</td>\n",
       "      <td>509869.725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>351509.998</td>\n",
       "      <td>188730.587</td>\n",
       "      <td>147723.892</td>\n",
       "      <td>0.000</td>\n",
       "      <td>835.760</td>\n",
       "      <td>15106.759</td>\n",
       "      <td>1958.416</td>\n",
       "      <td>291.777</td>\n",
       "      <td>2966.955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109250.039</td>\n",
       "      <td>23.361</td>\n",
       "      <td>109273.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Poland</td>\n",
       "      <td>2018</td>\n",
       "      <td>1267323.825</td>\n",
       "      <td>572778.420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346439.617</td>\n",
       "      <td>187523.320</td>\n",
       "      <td>142875.170</td>\n",
       "      <td>0.000</td>\n",
       "      <td>662.043</td>\n",
       "      <td>12798.792</td>\n",
       "      <td>1969.997</td>\n",
       "      <td>275.296</td>\n",
       "      <td>2488.450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109250.464</td>\n",
       "      <td>22.527</td>\n",
       "      <td>109272.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Poland</td>\n",
       "      <td>2017</td>\n",
       "      <td>1213879.094</td>\n",
       "      <td>577683.390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338653.065</td>\n",
       "      <td>179624.048</td>\n",
       "      <td>105218.913</td>\n",
       "      <td>0.000</td>\n",
       "      <td>633.464</td>\n",
       "      <td>14909.041</td>\n",
       "      <td>2559.581</td>\n",
       "      <td>262.649</td>\n",
       "      <td>2134.233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73161.750</td>\n",
       "      <td>21.956</td>\n",
       "      <td>73183.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Poland</td>\n",
       "      <td>2016</td>\n",
       "      <td>1161827.825</td>\n",
       "      <td>576113.505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301033.707</td>\n",
       "      <td>170186.500</td>\n",
       "      <td>103619.724</td>\n",
       "      <td>0.000</td>\n",
       "      <td>608.056</td>\n",
       "      <td>12587.590</td>\n",
       "      <td>2139.446</td>\n",
       "      <td>258.333</td>\n",
       "      <td>1824.858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76992.500</td>\n",
       "      <td>20.856</td>\n",
       "      <td>77013.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Czechia</td>\n",
       "      <td>2015</td>\n",
       "      <td>485637.458</td>\n",
       "      <td>190669.319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100142.154</td>\n",
       "      <td>75394.500</td>\n",
       "      <td>50995.877</td>\n",
       "      <td>77692.497</td>\n",
       "      <td>183.836</td>\n",
       "      <td>572.610</td>\n",
       "      <td>1794.769</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1256.091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33421.944</td>\n",
       "      <td>0.000</td>\n",
       "      <td>33421.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Czechia</td>\n",
       "      <td>2014</td>\n",
       "      <td>485202.472</td>\n",
       "      <td>185755.248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102476.155</td>\n",
       "      <td>71898.000</td>\n",
       "      <td>49645.373</td>\n",
       "      <td>88745.807</td>\n",
       "      <td>171.855</td>\n",
       "      <td>476.544</td>\n",
       "      <td>1908.749</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1098.968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32134.167</td>\n",
       "      <td>0.000</td>\n",
       "      <td>32134.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Czechia</td>\n",
       "      <td>2013</td>\n",
       "      <td>501981.172</td>\n",
       "      <td>200923.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96327.105</td>\n",
       "      <td>80786.750</td>\n",
       "      <td>48042.219</td>\n",
       "      <td>90231.594</td>\n",
       "      <td>159.075</td>\n",
       "      <td>480.519</td>\n",
       "      <td>2734.507</td>\n",
       "      <td>0.000</td>\n",
       "      <td>957.408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30819.167</td>\n",
       "      <td>0.000</td>\n",
       "      <td>30819.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Czechia</td>\n",
       "      <td>2012</td>\n",
       "      <td>499492.160</td>\n",
       "      <td>201002.605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100292.171</td>\n",
       "      <td>79736.500</td>\n",
       "      <td>43695.767</td>\n",
       "      <td>89248.451</td>\n",
       "      <td>146.117</td>\n",
       "      <td>415.817</td>\n",
       "      <td>2129.143</td>\n",
       "      <td>0.000</td>\n",
       "      <td>815.528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29505.278</td>\n",
       "      <td>0.000</td>\n",
       "      <td>29505.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Czechia</td>\n",
       "      <td>2011</td>\n",
       "      <td>503665.845</td>\n",
       "      <td>212838.430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101691.766</td>\n",
       "      <td>79190.500</td>\n",
       "      <td>40684.339</td>\n",
       "      <td>83734.255</td>\n",
       "      <td>127.186</td>\n",
       "      <td>397.003</td>\n",
       "      <td>1963.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>678.172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28011.944</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28011.944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Country  Year    Total_GWH  Solid_fossil_fuels  Peat_and_peat_products  \\\n",
       "22    Poland  2020  1192325.452          475838.038                     0.0   \n",
       "64    Poland  2019  1221101.488          509869.725                     0.0   \n",
       "106   Poland  2018  1267323.825          572778.420                     0.0   \n",
       "148   Poland  2017  1213879.094          577683.390                     0.0   \n",
       "190   Poland  2016  1161827.825          576113.505                     0.0   \n",
       "..       ...   ...          ...                 ...                     ...   \n",
       "214  Czechia  2015   485637.458          190669.319                     0.0   \n",
       "256  Czechia  2014   485202.472          185755.248                     0.0   \n",
       "298  Czechia  2013   501981.172          200923.005                     0.0   \n",
       "340  Czechia  2012   499492.160          201002.605                     0.0   \n",
       "382  Czechia  2011   503665.845          212838.430                     0.0   \n",
       "\n",
       "     Oil_and_petroleum_products  Natural_gas  Renewables_and_biofuels  \\\n",
       "22                   337028.005   202831.135               150618.088   \n",
       "64                   351509.998   188730.587               147723.892   \n",
       "106                  346439.617   187523.320               142875.170   \n",
       "148                  338653.065   179624.048               105218.913   \n",
       "190                  301033.707   170186.500               103619.724   \n",
       "..                          ...          ...                      ...   \n",
       "214                  100142.154    75394.500                50995.877   \n",
       "256                  102476.155    71898.000                49645.373   \n",
       "298                   96327.105    80786.750                48042.219   \n",
       "340                  100292.171    79736.500                43695.767   \n",
       "382                  101691.766    79190.500                40684.339   \n",
       "\n",
       "     Nuclear_heat  Solar_Thermal       Wind     Hydro  Geothermal  \\\n",
       "22          0.000        932.074  15800.049  2118.337     298.189   \n",
       "64          0.000        835.760  15106.759  1958.416     291.777   \n",
       "106         0.000        662.043  12798.792  1969.997     275.296   \n",
       "148         0.000        633.464  14909.041  2559.581     262.649   \n",
       "190         0.000        608.056  12587.590  2139.446     258.333   \n",
       "..            ...            ...        ...       ...         ...   \n",
       "214     77692.497        183.836    572.610  1794.769       0.000   \n",
       "256     88745.807        171.855    476.544  1908.749       0.000   \n",
       "298     90231.594        159.075    480.519  2734.507       0.000   \n",
       "340     89248.451        146.117    415.817  2129.143       0.000   \n",
       "382     83734.255        127.186    397.003  1963.016       0.000   \n",
       "\n",
       "     Ambient_Heat  Tide_wave_and_ocean  Biofuels_solid  Biofuels_other  \\\n",
       "22       3467.032                  0.0      108513.529          22.718   \n",
       "64       2966.955                  0.0      109250.039          23.361   \n",
       "106      2488.450                  0.0      109250.464          22.527   \n",
       "148      2134.233                  0.0       73161.750          21.956   \n",
       "190      1824.858                  0.0       76992.500          20.856   \n",
       "..            ...                  ...             ...             ...   \n",
       "214      1256.091                  0.0       33421.944           0.000   \n",
       "256      1098.968                  0.0       32134.167           0.000   \n",
       "298       957.408                  0.0       30819.167           0.000   \n",
       "340       815.528                  0.0       29505.278           0.000   \n",
       "382       678.172                  0.0       28011.944           0.000   \n",
       "\n",
       "       Biofuels  \n",
       "22   108536.247  \n",
       "64   109273.400  \n",
       "106  109272.991  \n",
       "148   73183.706  \n",
       "190   77013.356  \n",
       "..          ...  \n",
       "214   33421.944  \n",
       "256   32134.167  \n",
       "298   30819.167  \n",
       "340   29505.278  \n",
       "382   28011.944  \n",
       "\n",
       "[420 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdat = data_impute.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df872da6-87e2-486c-8d98-d44dc49c27e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6256\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.0235\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.7991\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.8408\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.9547\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9900\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0003\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.0017\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9998\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9967\n",
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    }
   ],
   "source": [
    "n_assets = 12\n",
    "data = cdat\n",
    "    \n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = None\n",
    "        \n",
    "        # self.callback = EarlyStopping(monitor='loss', min_delta=.1, patience = 10)\n",
    "    \n",
    "    def __build_model(self, input_shape, outputs):\n",
    "        model = Sequential([\n",
    "            LSTM(64, input_shape=input_shape, activation='relu'),\n",
    "            Flatten(),\n",
    "            Dense(outputs, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        def sharpe_loss(_, y_pred):\n",
    "            coeffs = tf.tile(y_pred, (self.data.shape[0], 1))\n",
    "            \n",
    "            portfolio_values = tf.reduce_sum(tf.multiply(coeffs, self.data), axis=1)\n",
    "            \n",
    "            portfolio_returns = (portfolio_values[1:] - portfolio_values[:-1]) / portfolio_values[:-1]  # % change formula\n",
    "\n",
    "            sharpe = K.mean(portfolio_returns) / K.std(portfolio_returns)\n",
    "            \n",
    "            # exp keeps relative ordering between positives and negatives\n",
    "            #   since we want to maximize sharp, while gradient descent minimizes the loss\n",
    "            #   we negate the Sharpe value\n",
    "            return K.exp(-sharpe)\n",
    "        \n",
    "        model.compile(loss=sharpe_loss, optimizer='adam')\n",
    "        return model\n",
    "    \n",
    "    def get_allocations(self, data):\n",
    "        \n",
    "        \n",
    "        # data with returns\n",
    "        data_w_ret = np.concatenate([ data.values[1:], data.pct_change().values[1:] ], axis=1)\n",
    "        \n",
    "        data = data.iloc[1:]\n",
    "        self.data = tf.cast(tf.constant(data), float)\n",
    "        \n",
    "        if self.model is None:\n",
    "            self.model = self.__build_model(data_w_ret.shape, len(data.columns))\n",
    "        \n",
    "        fit_predict_data = data_w_ret[np.newaxis,:]        \n",
    "        self.model.fit(fit_predict_data, np.zeros((1, len(data.columns))), epochs=10, shuffle=False)\n",
    "        return self.model.predict(fit_predict_data)[0]\n",
    "    \n",
    "model = Model() \n",
    "weights = model.get_allocations(pd.DataFrame(np.random.randn(n_assets,n_assets)))\n",
    "weight_fulldata = weights\n",
    "#return_fulldata = np.zeros(weight_fulldata.shape)\n",
    "#risks_fulldata = np.zeros(weight_fulldata.shape)\n",
    "#for j in range(n_assets):\n",
    "#    return_fulldata[j] = np.sum(weight_fulldata[j] * data[i][j])\n",
    "#    risks_fulldata[j] = weight_fulldata[i,j] * np.diagonal(np.cov(data[i].T))[j] * weight_fulldata[i,j]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65752cba-28fb-4ff9-9990-c9ec537ff608",
   "metadata": {},
   "source": [
    "Drop one country at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c49e17b2-4e52-40df-ab86-a03dcdd925d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full data with country and year\n",
    "cdat = data_impute.loc[:,['Country','Year','Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "751ccb9c-887c-4c92-9335-5a7b07c35cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_country = np.zeros((len(data_impute.groupby('Country')),len(cdat.T)-2))\n",
    "return_country = np.zeros((len(data_impute.groupby('Country')),len(cdat.T)-2))\n",
    "risks_country = np.zeros((len(data_impute.groupby('Country')),len(cdat.T)-2))\n",
    "\n",
    "for i in range(len(data_impute.groupby('Country'))):\n",
    "    country_dat = cdat.loc[(cdat.Country != cdat.Country.unique()[i])]\n",
    "    country_dat = country_dat.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]\n",
    "    data = country_dat\n",
    "    \n",
    "    class Model:\n",
    "        def __init__(self):\n",
    "            self.data = None\n",
    "            self.model = None\n",
    "        \n",
    "            # self.callback = EarlyStopping(monitor='loss', min_delta=.1, patience = 10)\n",
    "    \n",
    "        def __build_model(self, input_shape, outputs):\n",
    "            model = Sequential([\n",
    "                LSTM(64, input_shape=input_shape, activation='relu'),\n",
    "                Flatten(),\n",
    "                Dense(outputs, activation='softmax')\n",
    "            ])\n",
    "\n",
    "            def sharpe_loss(_, y_pred):\n",
    "                coeffs = tf.tile(y_pred, (self.data.shape[0], 1))\n",
    "            \n",
    "                portfolio_values = tf.reduce_sum(tf.multiply(coeffs, self.data), axis=1)\n",
    "            \n",
    "                portfolio_returns = (portfolio_values[1:] - portfolio_values[:-1]) / portfolio_values[:-1]  # % change formula\n",
    "\n",
    "                sharpe = K.mean(portfolio_returns) / K.std(portfolio_returns)\n",
    "            \n",
    "                # exp keeps relative ordering between positives and negatives\n",
    "                #   since we want to maximize sharp, while gradient descent minimizes the loss\n",
    "                #   we negate the Sharpe value\n",
    "                return K.exp(-sharpe)\n",
    "        \n",
    "            model.compile(loss=sharpe_loss, optimizer='adam')\n",
    "            return model\n",
    "    \n",
    "        def get_allocations(self, data):\n",
    "        \n",
    "        \n",
    "            # data with returns\n",
    "            data_w_ret = np.concatenate([ data.values[1:], data.pct_change().values[1:] ], axis=1)\n",
    "        \n",
    "            data = data.iloc[1:]\n",
    "            self.data = tf.cast(tf.constant(data), float)\n",
    "        \n",
    "            if self.model is None:\n",
    "                self.model = self.__build_model(data_w_ret.shape, len(data.columns))\n",
    "        \n",
    "            fit_predict_data = data_w_ret[np.newaxis,:]        \n",
    "            self.model.fit(fit_predict_data, np.zeros((1, len(data.columns))), epochs=10, shuffle=False)\n",
    "            return self.model.predict(fit_predict_data)[0]\n",
    "    \n",
    "    model = Model() \n",
    "    weights = model.get_allocations(pd.DataFrame(np.random.randn(n_assets,n_assets)))\n",
    "    weight_country[i,:] = weights\n",
    "    #for j in range(n_assets):\n",
    "    #    return_n8_corr[i,j] = np.sum(weight_n8_corr[i,j] * data_n8_corr[i][j])\n",
    "    #    risks_n8_corr[i,j] = weight_n8_corr[i,j] * np.diagonal(np.cov(data_n8_corr[i].T))[j] * weight_n8_corr[i,j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0162f2b9-6f70-4cf5-a16d-1d8ff821fe9f",
   "metadata": {},
   "source": [
    "Drop one year at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40ee6c36-73cd-45d1-a19b-7551e6e44991",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_year = np.zeros((len(data_impute.groupby('Year')),len(cdat.T)-2))\n",
    "return_year = np.zeros((len(data_impute.groupby('Year')),len(cdat.T)-2))\n",
    "risks_year = np.zeros((len(data_impute.groupby('Year')),len(cdat.T)-2))\n",
    "\n",
    "for i in range(len(data_impute.groupby('Year'))):\n",
    "    year_dat = cdat.loc[(cdat.Year != cdat.Year.unique()[i])]\n",
    "    year_dat = country_dat.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]\n",
    "    data = country_dat\n",
    "    \n",
    "    class Model:\n",
    "        def __init__(self):\n",
    "            self.data = None\n",
    "            self.model = None\n",
    "        \n",
    "            # self.callback = EarlyStopping(monitor='loss', min_delta=.1, patience = 10)\n",
    "    \n",
    "        def __build_model(self, input_shape, outputs):\n",
    "            model = Sequential([\n",
    "                LSTM(64, input_shape=input_shape, activation='relu'),\n",
    "                Flatten(),\n",
    "                Dense(outputs, activation='softmax')\n",
    "            ])\n",
    "\n",
    "            def sharpe_loss(_, y_pred):\n",
    "                coeffs = tf.tile(y_pred, (self.data.shape[0], 1))\n",
    "            \n",
    "                portfolio_values = tf.reduce_sum(tf.multiply(coeffs, self.data), axis=1)\n",
    "            \n",
    "                portfolio_returns = (portfolio_values[1:] - portfolio_values[:-1]) / portfolio_values[:-1]  # % change formula\n",
    "\n",
    "                sharpe = K.mean(portfolio_returns) / K.std(portfolio_returns)\n",
    "            \n",
    "                # exp keeps relative ordering between positives and negatives\n",
    "                #   since we want to maximize sharp, while gradient descent minimizes the loss\n",
    "                #   we negate the Sharpe value\n",
    "                return K.exp(-sharpe)\n",
    "        \n",
    "            model.compile(loss=sharpe_loss, optimizer='adam')\n",
    "            return model\n",
    "    \n",
    "        def get_allocations(self, data):\n",
    "        \n",
    "        \n",
    "            # data with returns\n",
    "            data_w_ret = np.concatenate([ data.values[1:], data.pct_change().values[1:] ], axis=1)\n",
    "        \n",
    "            data = data.iloc[1:]\n",
    "            self.data = tf.cast(tf.constant(data), float)\n",
    "        \n",
    "            if self.model is None:\n",
    "                self.model = self.__build_model(data_w_ret.shape, len(data.columns))\n",
    "        \n",
    "            fit_predict_data = data_w_ret[np.newaxis,:]        \n",
    "            self.model.fit(fit_predict_data, np.zeros((1, len(data.columns))), epochs=10, shuffle=False)\n",
    "            return self.model.predict(fit_predict_data)[0]\n",
    "    \n",
    "    model = Model() \n",
    "    weights = model.get_allocations(pd.DataFrame(np.random.randn(n_assets,n_assets)))\n",
    "    weight_year[i,:] = weights\n",
    "    #for j in range(n_assets):\n",
    "    #    return_n8_corr[i,j] = np.sum(weight_n8_corr[i,j] * data_n8_corr[i][j])\n",
    "    #    risks_n8_corr[i,j] = weight_n8_corr[i,j] * np.diagonal(np.cov(data_n8_corr[i].T))[j] * weight_n8_corr[i,j]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c306f8-4521-496b-9fe9-df195cdd8b91",
   "metadata": {},
   "source": [
    "Drop random 20% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbd9e43a-b148-4999-bb97-b643b82d165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_rand = np.zeros((100,len(cdat.T)-2))\n",
    "return_rand = np.zeros((100,len(cdat.T)-2))\n",
    "risks_rand = np.zeros((100,len(cdat.T)-2))\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    # Randomly take out 20% of the data\n",
    "    _80_perct = int(cdat.shape[0]*4/5)\n",
    "    cdat = cdat.iloc[random.sample(list(range(cdat.shape[0])), _80_perct)]\n",
    "    data = cdat.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]\n",
    "    class Model:\n",
    "        def __init__(self):\n",
    "            self.data = None\n",
    "            self.model = None\n",
    "        \n",
    "            # self.callback = EarlyStopping(monitor='loss', min_delta=.1, patience = 10)\n",
    "    \n",
    "        def __build_model(self, input_shape, outputs):\n",
    "            model = Sequential([\n",
    "                LSTM(64, input_shape=input_shape, activation='relu'),\n",
    "                Flatten(),\n",
    "                Dense(outputs, activation='softmax')\n",
    "            ])\n",
    "\n",
    "            def sharpe_loss(_, y_pred):\n",
    "                coeffs = tf.tile(y_pred, (self.data.shape[0], 1))\n",
    "            \n",
    "                portfolio_values = tf.reduce_sum(tf.multiply(coeffs, self.data), axis=1)\n",
    "            \n",
    "                portfolio_returns = (portfolio_values[1:] - portfolio_values[:-1]) / portfolio_values[:-1]  # % change formula\n",
    "\n",
    "                sharpe = K.mean(portfolio_returns) / K.std(portfolio_returns)\n",
    "            \n",
    "                # exp keeps relative ordering between positives and negatives\n",
    "                #   since we want to maximize sharp, while gradient descent minimizes the loss\n",
    "                #   we negate the Sharpe value\n",
    "                return K.exp(-sharpe)\n",
    "        \n",
    "            model.compile(loss=sharpe_loss, optimizer='adam')\n",
    "            return model\n",
    "    \n",
    "        def get_allocations(self, data):\n",
    "        \n",
    "        \n",
    "            # data with returns\n",
    "            data_w_ret = np.concatenate([ data.values[1:], data.pct_change().values[1:] ], axis=1)\n",
    "        \n",
    "            data = data.iloc[1:]\n",
    "            self.data = tf.cast(tf.constant(data), float)\n",
    "        \n",
    "            if self.model is None:\n",
    "                self.model = self.__build_model(data_w_ret.shape, len(data.columns))\n",
    "        \n",
    "            fit_predict_data = data_w_ret[np.newaxis,:]        \n",
    "            self.model.fit(fit_predict_data, np.zeros((1, len(data.columns))), epochs=10, shuffle=False)\n",
    "            return self.model.predict(fit_predict_data)[0]\n",
    "    \n",
    "    model = Model() \n",
    "    weights = model.get_allocations(pd.DataFrame(np.random.randn(n_assets,n_assets)))\n",
    "    weight_rand[i,:] = weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8725afc-25b3-41da-9148-d1d81cb8c9bb",
   "metadata": {},
   "source": [
    "## Repeat this while dropping missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e0cf58a-b649-4d12-9b1f-8eafb0f9ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop = data_full.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec8c291-c261-43fc-b07c-242cf6df46be",
   "metadata": {},
   "source": [
    "Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92409b71-daae-4670-aea8-1efc07b29742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full data with country and year\n",
    "cdat = data_drop.loc[:,['Country','Year','Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86d0a924-ef2b-4d1c-9c9e-3b9d93547993",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_assets = 12\n",
    "data = cdat\n",
    "    \n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = None\n",
    "        \n",
    "        # self.callback = EarlyStopping(monitor='loss', min_delta=.1, patience = 10)\n",
    "    \n",
    "    def __build_model(self, input_shape, outputs):\n",
    "        model = Sequential([\n",
    "            LSTM(64, input_shape=input_shape, activation='relu'),\n",
    "            Flatten(),\n",
    "            Dense(outputs, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        def sharpe_loss(_, y_pred):\n",
    "            coeffs = tf.tile(y_pred, (self.data.shape[0], 1))\n",
    "            \n",
    "            portfolio_values = tf.reduce_sum(tf.multiply(coeffs, self.data), axis=1)\n",
    "            \n",
    "            portfolio_returns = (portfolio_values[1:] - portfolio_values[:-1]) / portfolio_values[:-1]  # % change formula\n",
    "\n",
    "            sharpe = K.mean(portfolio_returns) / K.std(portfolio_returns)\n",
    "            \n",
    "            # exp keeps relative ordering between positives and negatives\n",
    "            #   since we want to maximize sharp, while gradient descent minimizes the loss\n",
    "            #   we negate the Sharpe value\n",
    "            return K.exp(-sharpe)\n",
    "        \n",
    "        model.compile(loss=sharpe_loss, optimizer='adam')\n",
    "        return model\n",
    "    \n",
    "    def get_allocations(self, data):\n",
    "        \n",
    "        \n",
    "        # data with returns\n",
    "        data_w_ret = np.concatenate([ data.values[1:], data.pct_change().values[1:] ], axis=1)\n",
    "        \n",
    "        data = data.iloc[1:]\n",
    "        self.data = tf.cast(tf.constant(data), float)\n",
    "        \n",
    "        if self.model is None:\n",
    "            self.model = self.__build_model(data_w_ret.shape, len(data.columns))\n",
    "        \n",
    "        fit_predict_data = data_w_ret[np.newaxis,:]        \n",
    "        self.model.fit(fit_predict_data, np.zeros((1, len(data.columns))), epochs=10, shuffle=False)\n",
    "        return self.model.predict(fit_predict_data)[0]\n",
    "    \n",
    "model = Model() \n",
    "weights = model.get_allocations(pd.DataFrame(np.random.randn(n_assets,n_assets)))\n",
    "weight_fulldata_drop = weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4905c9a-d934-4516-96dd-af31c8b49828",
   "metadata": {},
   "source": [
    "Drop one country at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee459000-17e2-482b-aea3-d6a9b4c8d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full data with country and year\n",
    "cdat = data_drop.loc[:,['Country','Year','Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e2e2292-28aa-4257-9513-e0f5a2ae9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_country_drop = np.zeros((len(data_impute.groupby('Country')),len(cdat.T)-2))\n",
    "return_country = np.zeros((len(data_impute.groupby('Country')),len(cdat.T)-2))\n",
    "risks_country = np.zeros((len(data_impute.groupby('Country')),len(cdat.T)-2))\n",
    "\n",
    "for i in range(len(data_impute.groupby('Country'))):\n",
    "    country_dat = cdat.loc[(cdat.Country != cdat.Country.unique()[i])]\n",
    "    country_dat = country_dat.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]\n",
    "    data = country_dat\n",
    "    \n",
    "    class Model:\n",
    "        def __init__(self):\n",
    "            self.data = None\n",
    "            self.model = None\n",
    "        \n",
    "            # self.callback = EarlyStopping(monitor='loss', min_delta=.1, patience = 10)\n",
    "    \n",
    "        def __build_model(self, input_shape, outputs):\n",
    "            model = Sequential([\n",
    "                LSTM(64, input_shape=input_shape, activation='relu'),\n",
    "                Flatten(),\n",
    "                Dense(outputs, activation='softmax')\n",
    "            ])\n",
    "\n",
    "            def sharpe_loss(_, y_pred):\n",
    "                coeffs = tf.tile(y_pred, (self.data.shape[0], 1))\n",
    "            \n",
    "                portfolio_values = tf.reduce_sum(tf.multiply(coeffs, self.data), axis=1)\n",
    "            \n",
    "                portfolio_returns = (portfolio_values[1:] - portfolio_values[:-1]) / portfolio_values[:-1]  # % change formula\n",
    "\n",
    "                sharpe = K.mean(portfolio_returns) / K.std(portfolio_returns)\n",
    "            \n",
    "                # exp keeps relative ordering between positives and negatives\n",
    "                #   since we want to maximize sharp, while gradient descent minimizes the loss\n",
    "                #   we negate the Sharpe value\n",
    "                return K.exp(-sharpe)\n",
    "        \n",
    "            model.compile(loss=sharpe_loss, optimizer='adam')\n",
    "            return model\n",
    "    \n",
    "        def get_allocations(self, data):\n",
    "        \n",
    "        \n",
    "            # data with returns\n",
    "            data_w_ret = np.concatenate([ data.values[1:], data.pct_change().values[1:] ], axis=1)\n",
    "        \n",
    "            data = data.iloc[1:]\n",
    "            self.data = tf.cast(tf.constant(data), float)\n",
    "        \n",
    "            if self.model is None:\n",
    "                self.model = self.__build_model(data_w_ret.shape, len(data.columns))\n",
    "        \n",
    "            fit_predict_data = data_w_ret[np.newaxis,:]        \n",
    "            self.model.fit(fit_predict_data, np.zeros((1, len(data.columns))), epochs=10, shuffle=False)\n",
    "            return self.model.predict(fit_predict_data)[0]\n",
    "    \n",
    "    model = Model() \n",
    "    weights = model.get_allocations(pd.DataFrame(np.random.randn(n_assets,n_assets)))\n",
    "    weight_country_drop[i,:] = weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4de43-a606-4c27-9617-400d52f51b90",
   "metadata": {},
   "source": [
    "Drop one year at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7ab5f14-e425-4dfd-b628-5f8bdec2a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_year_drop = np.zeros((len(data_impute.groupby('Year')),len(cdat.T)-2))\n",
    "return_year = np.zeros((len(data_impute.groupby('Year')),len(cdat.T)-2))\n",
    "risks_year = np.zeros((len(data_impute.groupby('Year')),len(cdat.T)-2))\n",
    "\n",
    "for i in range(len(data_impute.groupby('Year'))):\n",
    "    year_dat = cdat.loc[(cdat.Year != cdat.Year.unique()[i])]\n",
    "    year_dat = country_dat.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]\n",
    "    data = country_dat\n",
    "    \n",
    "    class Model:\n",
    "        def __init__(self):\n",
    "            self.data = None\n",
    "            self.model = None\n",
    "        \n",
    "            # self.callback = EarlyStopping(monitor='loss', min_delta=.1, patience = 10)\n",
    "    \n",
    "        def __build_model(self, input_shape, outputs):\n",
    "            model = Sequential([\n",
    "                LSTM(64, input_shape=input_shape, activation='relu'),\n",
    "                Flatten(),\n",
    "                Dense(outputs, activation='softmax')\n",
    "            ])\n",
    "\n",
    "            def sharpe_loss(_, y_pred):\n",
    "                coeffs = tf.tile(y_pred, (self.data.shape[0], 1))\n",
    "            \n",
    "                portfolio_values = tf.reduce_sum(tf.multiply(coeffs, self.data), axis=1)\n",
    "            \n",
    "                portfolio_returns = (portfolio_values[1:] - portfolio_values[:-1]) / portfolio_values[:-1]  # % change formula\n",
    "\n",
    "                sharpe = K.mean(portfolio_returns) / K.std(portfolio_returns)\n",
    "            \n",
    "                # exp keeps relative ordering between positives and negatives\n",
    "                #   since we want to maximize sharp, while gradient descent minimizes the loss\n",
    "                #   we negate the Sharpe value\n",
    "                return K.exp(-sharpe)\n",
    "        \n",
    "            model.compile(loss=sharpe_loss, optimizer='adam')\n",
    "            return model\n",
    "    \n",
    "        def get_allocations(self, data):\n",
    "        \n",
    "        \n",
    "            # data with returns\n",
    "            data_w_ret = np.concatenate([ data.values[1:], data.pct_change().values[1:] ], axis=1)\n",
    "        \n",
    "            data = data.iloc[1:]\n",
    "            self.data = tf.cast(tf.constant(data), float)\n",
    "        \n",
    "            if self.model is None:\n",
    "                self.model = self.__build_model(data_w_ret.shape, len(data.columns))\n",
    "        \n",
    "            fit_predict_data = data_w_ret[np.newaxis,:]        \n",
    "            self.model.fit(fit_predict_data, np.zeros((1, len(data.columns))), epochs=10, shuffle=False)\n",
    "            return self.model.predict(fit_predict_data)[0]\n",
    "    \n",
    "    model = Model() \n",
    "    weights = model.get_allocations(pd.DataFrame(np.random.randn(n_assets,n_assets)))\n",
    "    weight_year_drop[i,:] = weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d704dd-0f93-4295-b27c-a8ddab041600",
   "metadata": {},
   "source": [
    "Drop random 20% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df7ffdaa-ee30-46fa-ab26-8d827add6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_rand_drop = np.zeros((100,len(cdat.T)-2))\n",
    "return_rand = np.zeros((100,len(cdat.T)-2))\n",
    "risks_rand = np.zeros((100,len(cdat.T)-2))\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    # Randomly take out 20% of the data\n",
    "    _80_perct = int(cdat.shape[0]*4/5)\n",
    "    cdat = cdat.iloc[random.sample(list(range(cdat.shape[0])), _80_perct)]\n",
    "    data = cdat.loc[:,['Solid_fossil_fuels','Peat_and_peat_products','Oil_and_petroleum_products', \n",
    "                          'Natural_gas', 'Nuclear_heat', 'Hydro', 'Solar_Thermal', 'Geothermal', \n",
    "                          'Ambient_Heat', 'Tide_wave_and_ocean', 'Biofuels_solid', 'Biofuels_other']]\n",
    "    class Model:\n",
    "        def __init__(self):\n",
    "            self.data = None\n",
    "            self.model = None\n",
    "        \n",
    "            # self.callback = EarlyStopping(monitor='loss', min_delta=.1, patience = 10)\n",
    "    \n",
    "        def __build_model(self, input_shape, outputs):\n",
    "            model = Sequential([\n",
    "                LSTM(64, input_shape=input_shape, activation='relu'),\n",
    "                Flatten(),\n",
    "                Dense(outputs, activation='softmax')\n",
    "            ])\n",
    "\n",
    "            def sharpe_loss(_, y_pred):\n",
    "                coeffs = tf.tile(y_pred, (self.data.shape[0], 1))\n",
    "            \n",
    "                portfolio_values = tf.reduce_sum(tf.multiply(coeffs, self.data), axis=1)\n",
    "            \n",
    "                portfolio_returns = (portfolio_values[1:] - portfolio_values[:-1]) / portfolio_values[:-1]  # % change formula\n",
    "\n",
    "                sharpe = K.mean(portfolio_returns) / K.std(portfolio_returns)\n",
    "            \n",
    "                # exp keeps relative ordering between positives and negatives\n",
    "                #   since we want to maximize sharp, while gradient descent minimizes the loss\n",
    "                #   we negate the Sharpe value\n",
    "                return K.exp(-sharpe)\n",
    "        \n",
    "            model.compile(loss=sharpe_loss, optimizer='adam')\n",
    "            return model\n",
    "    \n",
    "        def get_allocations(self, data):\n",
    "        \n",
    "        \n",
    "            # data with returns\n",
    "            data_w_ret = np.concatenate([ data.values[1:], data.pct_change().values[1:] ], axis=1)\n",
    "        \n",
    "            data = data.iloc[1:]\n",
    "            self.data = tf.cast(tf.constant(data), float)\n",
    "        \n",
    "            if self.model is None:\n",
    "                self.model = self.__build_model(data_w_ret.shape, len(data.columns))\n",
    "        \n",
    "            fit_predict_data = data_w_ret[np.newaxis,:]        \n",
    "            self.model.fit(fit_predict_data, np.zeros((1, len(data.columns))), epochs=10, shuffle=False)\n",
    "            return self.model.predict(fit_predict_data)[0]\n",
    "    \n",
    "    model = Model() \n",
    "    weights = model.get_allocations(pd.DataFrame(np.random.randn(n_assets,n_assets)))\n",
    "    weight_rand_drop[i,:] = weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b54884a-d25e-46f8-aff2-9c420869b7cc",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b63ff3eb-718a-40e3-9db6-0592aa5b332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepLearningResults_Weights = [weight_fulldata, weight_country, weight_year, weight_rand, \n",
    "                              weight_fulldata_drop, weight_country_drop, weight_year_drop, weight_rand_drop]\n",
    "\n",
    "file_name = \"EUDeepLearningResultsWeights.pkl\"\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(DeepLearningResults_Weights, open_file)\n",
    "open_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
